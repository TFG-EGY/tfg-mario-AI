{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fc1c8bb5-4122-470e-bcad-8ca1a88b6b0e",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "source": [
    "# Play Super Mario Bros with a Double Deep Q-Network\n",
    "\n",
    "For a more detailed breakdown of the code, check out the full tutorial [on the Paperspace blog](https://blog.paperspace.com/building-double-deep-q-network-super-mario-bros/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1743fb07-3882-47d8-9547-c8e610c9ab48",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a25a5da2-12b5-486d-aa3c-b59bab21a49d",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            self._obs_buffer.append(obs)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Clear past frame buffer and init to first obs\"\"\"\n",
    "        self._obs_buffer.clear()\n",
    "        obs = self.env.reset()\n",
    "        self._obs_buffer.append(obs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Downsamples image to 84x84\n",
    "    Greyscales image\n",
    "\n",
    "    Returns numpy array\n",
    "    \"\"\"\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 240 * 256 * 3:\n",
    "            img = np.reshape(frame, [240, 256, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "def make_env(env):\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    return JoypadSpace(env, RIGHT_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ec902a7a-3600-4768-b27c-e0fdd5fd75bf",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "outputs": [],
   "source": [
    "class DQNSolver(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQNSolver, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)\n",
    "    \n",
    "\n",
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, state_space, action_space, max_memory_size, batch_size, gamma, lr,\n",
    "                 dropout, exploration_max, exploration_min, exploration_decay, double_dq, pretrained):\n",
    "\n",
    "        # Define DQN Layers\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.double_dq = double_dq\n",
    "        self.pretrained = pretrained\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        if self.double_dq:  \n",
    "            self.local_net = DQNSolver(state_space, action_space).to(self.device)\n",
    "            self.target_net = DQNSolver(state_space, action_space).to(self.device)\n",
    "            \n",
    "            if self.pretrained:\n",
    "                self.local_net.load_state_dict(torch.load(\"dq1.pt\", map_location=torch.device(self.device)))\n",
    "                self.target_net.load_state_dict(torch.load(\"dq2.pt\", map_location=torch.device(self.device)))\n",
    "                    \n",
    "            self.optimizer = torch.optim.Adam(self.local_net.parameters(), lr=lr)\n",
    "            self.copy = 5000  # Copy the local model weights into the target network every 5000 steps\n",
    "            self.step = 0\n",
    "        else:  \n",
    "            self.dqn = DQNSolver(state_space, action_space).to(self.device)\n",
    "            \n",
    "            if self.pretrained:\n",
    "                self.dqn.load_state_dict(torch.load(\"dq.pt\", map_location=torch.device(self.device)))\n",
    "            self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=lr)\n",
    "\n",
    "        # Create memory\n",
    "        self.max_memory_size = max_memory_size\n",
    "        if self.pretrained:\n",
    "            self.STATE_MEM = torch.load(\"STATE_MEM.pt\")\n",
    "            self.ACTION_MEM = torch.load(\"ACTION_MEM.pt\")\n",
    "            self.REWARD_MEM = torch.load(\"REWARD_MEM.pt\")\n",
    "            self.STATE2_MEM = torch.load(\"STATE2_MEM.pt\")\n",
    "            self.DONE_MEM = torch.load(\"DONE_MEM.pt\")\n",
    "            with open(\"ending_position.pkl\", 'rb') as f:\n",
    "                self.ending_position = pickle.load(f)\n",
    "            with open(\"num_in_queue.pkl\", 'rb') as f:\n",
    "                self.num_in_queue = pickle.load(f)\n",
    "        else:\n",
    "            self.STATE_MEM = torch.zeros(max_memory_size, *self.state_space)\n",
    "            self.ACTION_MEM = torch.zeros(max_memory_size, 1)\n",
    "            self.REWARD_MEM = torch.zeros(max_memory_size, 1)\n",
    "            self.STATE2_MEM = torch.zeros(max_memory_size, *self.state_space)\n",
    "            self.DONE_MEM = torch.zeros(max_memory_size, 1)\n",
    "            self.ending_position = 0\n",
    "            self.num_in_queue = 0\n",
    "        \n",
    "        self.memory_sample_size = batch_size\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.gamma = gamma\n",
    "        self.l1 = nn.SmoothL1Loss().to(self.device) # Also known as Huber loss\n",
    "        self.exploration_max = exploration_max\n",
    "        self.exploration_rate = exploration_max\n",
    "        self.exploration_min = exploration_min\n",
    "        self.exploration_decay = exploration_decay\n",
    "\n",
    "    def remember(self, state, action, reward, state2, done):\n",
    "        self.STATE_MEM[self.ending_position] = state.float()\n",
    "        self.ACTION_MEM[self.ending_position] = action.float()\n",
    "        self.REWARD_MEM[self.ending_position] = reward.float()\n",
    "        self.STATE2_MEM[self.ending_position] = state2.float()\n",
    "        self.DONE_MEM[self.ending_position] = done.float()\n",
    "        self.ending_position = (self.ending_position + 1) % self.max_memory_size  # FIFO tensor\n",
    "        self.num_in_queue = min(self.num_in_queue + 1, self.max_memory_size)\n",
    "        \n",
    "    def recall(self):\n",
    "        # Randomly sample 'batch size' experiences\n",
    "        idx = random.choices(range(self.num_in_queue), k=self.memory_sample_size)\n",
    "        \n",
    "        STATE = self.STATE_MEM[idx]\n",
    "        ACTION = self.ACTION_MEM[idx]\n",
    "        REWARD = self.REWARD_MEM[idx]\n",
    "        STATE2 = self.STATE2_MEM[idx]\n",
    "        DONE = self.DONE_MEM[idx]\n",
    "        \n",
    "        return STATE, ACTION, REWARD, STATE2, DONE\n",
    "\n",
    "    def act(self, state):\n",
    "        # Epsilon-greedy action\n",
    "        \n",
    "        if self.double_dq:\n",
    "            self.step += 1\n",
    "        if random.random() < self.exploration_rate:  \n",
    "            return torch.tensor([[random.randrange(self.action_space)]])\n",
    "        if self.double_dq:\n",
    "            # Local net is used for the policy\n",
    "            return torch.argmax(self.local_net(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "        else:\n",
    "            return torch.argmax(self.dqn(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "\n",
    "    def copy_model(self):\n",
    "        # Copy local net weights into target net\n",
    "        \n",
    "        self.target_net.load_state_dict(self.local_net.state_dict())\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        \n",
    "        if self.double_dq and self.step % self.copy == 0:\n",
    "            self.copy_model()\n",
    "\n",
    "        if self.memory_sample_size > self.num_in_queue:\n",
    "            return\n",
    "\n",
    "        STATE, ACTION, REWARD, STATE2, DONE = self.recall()\n",
    "        STATE = STATE.to(self.device)\n",
    "        ACTION = ACTION.to(self.device)\n",
    "        REWARD = REWARD.to(self.device)\n",
    "        STATE2 = STATE2.to(self.device)\n",
    "        DONE = DONE.to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        if self.double_dq:\n",
    "            # Double Q-Learning target is Q*(S, A) <- r + γ max_a Q_target(S', a)\n",
    "            target = REWARD + torch.mul((self.gamma * \n",
    "                                        self.target_net(STATE2).max(1).values.unsqueeze(1)), \n",
    "                                        1 - DONE)\n",
    "\n",
    "            current = self.local_net(STATE).gather(1, ACTION.long()) # Local net approximation of Q-value\n",
    "        else:\n",
    "            # Q-Learning target is Q*(S, A) <- r + γ max_a Q(S', a) \n",
    "            target = REWARD + torch.mul((self.gamma * \n",
    "                                        self.dqn(STATE2).max(1).values.unsqueeze(1)), \n",
    "                                        1 - DONE)\n",
    "                \n",
    "            current = self.dqn(STATE).gather(1, ACTION.long())\n",
    "        \n",
    "        loss = self.l1(current, target)\n",
    "        loss.backward() # Compute gradients\n",
    "        self.optimizer.step() # Backpropagate error\n",
    "\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "        \n",
    "        # Makes sure that exploration rate is always at least 'exploration min'\n",
    "        self.exploration_rate = max(self.exploration_rate, self.exploration_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "06f5332c-b7cc-4218-9956-d9f3a730bd09",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_action(action, action_space):\n",
    "    # Given a scalar action, return a one-hot encoded action\n",
    "    \n",
    "    return [0 for _ in range(action)] + [1] + [0 for _ in range(action + 1, action_space)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b913285f-bda1-4e21-9004-63c285157e67",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "outputs": [],
   "source": [
    "def show_state(env, ep=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"Episode: %d %s\" % (ep, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "71d55dc2-b4dc-46c7-aa26-32eabf60be95",
     "kernelId": "7db6d6b2-8ccc-43e5-ab66-1b0cdc830f14"
    }
   },
   "outputs": [],
   "source": [
    "def run(training_mode, pretrained):\n",
    "    print(\">>>Training starts at \", datetime.datetime.now())\n",
    "    env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "    env = make_env(env)  # Wraps the environment so that frames are grayscale \n",
    "    observation_space = env.observation_space.shape\n",
    "    action_space = env.action_space.n\n",
    "    agent = DQNAgent(state_space=observation_space,\n",
    "                     action_space=action_space,\n",
    "                     max_memory_size=30000,\n",
    "                     batch_size=32,\n",
    "                     gamma=0.90,\n",
    "                     lr=0.00025,\n",
    "                     dropout=0.,\n",
    "                     exploration_max=1.0,\n",
    "                     exploration_min=0.02,\n",
    "                     exploration_decay=0.99,\n",
    "                     double_dq=True,\n",
    "                     pretrained=pretrained)\n",
    "    \n",
    "    num_episodes = 2500\n",
    "    env.reset()\n",
    "    total_rewards = []\n",
    "    \n",
    "    for ep_num in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        state = torch.Tensor([state])\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        while True:\n",
    "            if not training_mode:\n",
    "                show_state(env, ep_num)\n",
    "            action = agent.act(state)\n",
    "            steps += 1\n",
    "            \n",
    "            state_next, reward, terminal, info = env.step(int(action[0]))\n",
    "            total_reward += reward\n",
    "            state_next = torch.Tensor([state_next])\n",
    "            reward = torch.tensor([reward]).unsqueeze(0)\n",
    "            \n",
    "            terminal = torch.tensor([int(terminal)]).unsqueeze(0)\n",
    "            \n",
    "            if training_mode:\n",
    "                agent.remember(state, action, reward, state_next, terminal)\n",
    "                agent.experience_replay()\n",
    "            \n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "        print(\"Total reward after episode {} is {}\".format(ep_num + 1, total_rewards[-1]))\n",
    "        num_episodes += 1      \n",
    "    \n",
    "    if training_mode:\n",
    "        with open(\"ending_position.pkl\", \"wb\") as f:\n",
    "            pickle.dump(agent.ending_position, f)\n",
    "        with open(\"num_in_queue.pkl\", \"wb\") as f:\n",
    "            pickle.dump(agent.num_in_queue, f)\n",
    "        with open(\"total_rewards.pkl\", \"wb\") as f:\n",
    "            pickle.dump(total_rewards, f)\n",
    "        if agent.double_dq:\n",
    "            torch.save(agent.local_net.state_dict(), \"dq1.pt\")\n",
    "            torch.save(agent.target_net.state_dict(), \"dq2.pt\")\n",
    "        else:\n",
    "            torch.save(agent.dqn.state_dict(), \"dq.pt\")  \n",
    "        torch.save(agent.STATE_MEM,  \"STATE_MEM.pt\")\n",
    "        torch.save(agent.ACTION_MEM, \"ACTION_MEM.pt\")\n",
    "        torch.save(agent.REWARD_MEM, \"REWARD_MEM.pt\")\n",
    "        torch.save(agent.STATE2_MEM, \"STATE2_MEM.pt\")\n",
    "        torch.save(agent.DONE_MEM,   \"DONE_MEM.pt\")\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    if num_episodes > 500:\n",
    "        plt.title(\"Episodes trained vs. Average Rewards (per 500 eps)\")\n",
    "        plt.plot([0 for _ in range(500)] + \n",
    "                 np.convolve(total_rewards, np.ones((500,))/500, mode=\"valid\").tolist())\n",
    "        plt.show()\n",
    "    print(\">>>Training ends at \", datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(training_mode=True, pretrained=False)\n",
    "print(\">>>Training ends at \", datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>>Testing ends at \", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 35/2500 [10:39<12:30:17, 18.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18656\\4127263342.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18656\\1394513130.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(training_mode, pretrained)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0msteps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mstate_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mstate_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_next\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# take the step and record the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18656\\587698213.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\entornoTFGgpu\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrollers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;31m# pass the action to the emulator as an unsigned byte\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;31m# get the reward for this step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run(training_mode=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
